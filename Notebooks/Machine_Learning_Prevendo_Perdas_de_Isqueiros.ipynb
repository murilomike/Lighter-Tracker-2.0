{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "LIGHTER TRACKER - SISTEMA DE PREDI√á√ÉO DE PERDA DE ISQUEIROS\n",
        "=============================================================================\n",
        "\n",
        "* Projeto: Sistema de Machine Learning para prever perda de isqueiros\n",
        "* Algoritmo: Regress√£o Log√≠stica (Classifica√ß√£o Bin√°ria)\n",
        "* Target: perdeu (True/False)\n",
        "* Objetivo: Fornecer recomenda√ß√µes aos usu√°rios sobre probabilidade de perda\n",
        "\n",
        "#### Autor: Murilo Souza, Cientista de Dados em Transi√ß√£o\n",
        "============================================================================\n"
      ],
      "metadata": {
        "id": "3dH_moH2KqYK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. IMPORTA√á√ÉO DAS BIBLIOTECAS"
      ],
      "metadata": {
        "id": "ea-kKc3gMyOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configura√ß√µes de exibi√ß√£o\n",
        "plt.style.use('seaborn-v0_8')\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)"
      ],
      "metadata": {
        "id": "hO-O_B3IM0xH"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. GERA√á√ÉO DA BASE SINT√âTICA DE DADOS"
      ],
      "metadata": {
        "id": "gO_RKKQJNXg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def gerar_base_sintetica(n_registros=1200, seed=42):\n",
        "    \"\"\"\n",
        "    Gera uma base sint√©tica de dados para o sistema Lighter Tracker\n",
        "\n",
        "    Par√¢metros:\n",
        "    - n_registros: N√∫mero de registros a serem gerados (padr√£o: 1200)\n",
        "    - seed: Seed para reprodutibilidade (padr√£o: 42)\n",
        "\n",
        "    Retorna:\n",
        "    - DataFrame com dados sint√©ticos de uso de isqueiros\n",
        "    \"\"\"\n",
        "\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "    print(f\"üîÑ Gerando {n_registros} registros sint√©ticos...\")\n",
        "\n",
        "    # Definindo as op√ß√µes categ√≥ricas baseadas no contexto real de uso\n",
        "    opcoes = {\n",
        "        'genero': ['M', 'F'],\n",
        "        'marcas': ['Bic', 'Zippo', 'Clipper', 'Cricket', 'Ronson', 'Generico'],\n",
        "        'cores': ['Azul', 'Preto', 'Branco', 'Vermelho', 'Verde', 'Amarelo', 'Prata', 'Dourado'],\n",
        "        'contextos_uso': ['Casa', 'Rua', 'Trabalho', 'Bar', 'Parque', 'Social', 'Festa', 'Carro'],\n",
        "        'propositos_uso': ['Cigarro', 'Tabaco', 'Vela', 'Incenso', 'Fogao', 'Camping', 'Charuto', 'Outro'],\n",
        "        'perfil_fumante': ['Pesado', 'Moderado', 'Social', 'Esporadico', 'Nao_fumante']\n",
        "    }\n",
        "\n",
        "    dados = []\n",
        "\n",
        "    # Data de in√≠cio: 1 ano atr√°s\n",
        "    data_inicio = datetime.now() - timedelta(days=365)\n",
        "\n",
        "    for i in range(n_registros):\n",
        "        # Caracter√≠sticas do usu√°rio\n",
        "        usuario_id = f\"USER_{i+1:04d}\"\n",
        "        nome = f\"Usuario_{i+1}\"\n",
        "        genero = np.random.choice(opcoes['genero'])\n",
        "        idade = np.random.randint(18, 65)\n",
        "\n",
        "        # Faixa et√°ria baseada na idade\n",
        "        if idade <= 25:\n",
        "            faixa_idade = '18-25'\n",
        "        elif idade <= 35:\n",
        "            faixa_idade = '26-35'\n",
        "        elif idade <= 50:\n",
        "            faixa_idade = '36-50'\n",
        "        else:\n",
        "            faixa_idade = '51+'\n",
        "\n",
        "        # Perfil de fumante (influencia no padr√£o de uso)\n",
        "        perfil_fumante = np.random.choice(opcoes['perfil_fumante'],\n",
        "                                        p=[0.15, 0.25, 0.30, 0.20, 0.10])\n",
        "\n",
        "        # Caracter√≠sticas do isqueiro\n",
        "        marca = np.random.choice(opcoes['marcas'],\n",
        "                               p=[0.35, 0.15, 0.20, 0.15, 0.10, 0.05])  # Bic √© mais comum\n",
        "        cor = np.random.choice(opcoes['cores'])\n",
        "        tipo_isqueiro = 'Descartavel' if marca in ['Bic', 'Cricket', 'Generico'] else 'Recarregavel'\n",
        "\n",
        "        # Pre√ßo baseado na marca\n",
        "        preco_base = {'Bic': 2.5, 'Zippo': 50.0, 'Clipper': 8.0,\n",
        "                     'Cricket': 1.5, 'Ronson': 15.0, 'Generico': 1.0}\n",
        "        preco_compra = preco_base[marca] + np.random.uniform(-0.5, 1.5)\n",
        "        preco_compra = max(preco_compra, 0.5)  # Pre√ßo m√≠nimo\n",
        "\n",
        "        # Datas\n",
        "        data_compra = data_inicio + timedelta(days=np.random.randint(0, 330))\n",
        "\n",
        "        # Tempo de posse (dias desde a compra at√© uso/perda)\n",
        "        # Isqueiros mais caros tendem a ser mantidos por mais tempo\n",
        "        if marca in ['Zippo', 'Ronson']:\n",
        "            tempo_posse = np.random.randint(30, 200)\n",
        "        else:\n",
        "            tempo_posse = np.random.randint(5, 120)\n",
        "\n",
        "        data_uso = data_compra + timedelta(days=tempo_posse)\n",
        "\n",
        "        # Padr√µes de uso baseados no perfil\n",
        "        multiplicador_uso = {'Pesado': 3.0, 'Moderado': 2.0, 'Social': 1.5,\n",
        "                           'Esporadico': 0.8, 'Nao_fumante': 0.3}\n",
        "\n",
        "        # N√∫mero de ascendimentos baseado no tempo de posse e perfil\n",
        "        ascendimentos_base = tempo_posse * multiplicador_uso[perfil_fumante]\n",
        "        num_ascendimentos = int(max(1, np.random.poisson(ascendimentos_base)))\n",
        "\n",
        "        # Frequ√™ncia de uso (ascendimentos por dia)\n",
        "        frequencia_uso = num_ascendimentos / max(tempo_posse, 1)\n",
        "\n",
        "        # Contexto e prop√≥sito de uso (com l√≥gica de probabilidade)\n",
        "        # Fumantes pesados usam mais na rua, n√£o fumantes mais em casa\n",
        "        if perfil_fumante in ['Pesado', 'Moderado']:\n",
        "            contexto_uso = np.random.choice(opcoes['contextos_uso'],\n",
        "                                          p=[0.20, 0.25, 0.15, 0.15, 0.10, 0.10, 0.03, 0.02])\n",
        "            proposito_uso = np.random.choice(opcoes['propositos_uso'],\n",
        "                                           p=[0.60, 0.25, 0.05, 0.05, 0.02, 0.02, 0.01, 0.00])\n",
        "        else:\n",
        "            contexto_uso = np.random.choice(opcoes['contextos_uso'],\n",
        "                                          p=[0.50, 0.10, 0.20, 0.05, 0.05, 0.05, 0.03, 0.02])\n",
        "            proposito_uso = np.random.choice(opcoes['propositos_uso'],\n",
        "                                           p=[0.20, 0.10, 0.25, 0.20, 0.15, 0.05, 0.03, 0.02])\n",
        "\n",
        "        # L√ìGICA PARA DEFINIR SE O ISQUEIRO FOI PERDIDO\n",
        "        # Fatores que aumentam a probabilidade de perda:\n",
        "        prob_perda = 0.2  # Base: 20%\n",
        "\n",
        "        # Contexto de uso (rua, bar, festa = maior risco)\n",
        "        if contexto_uso in ['Rua', 'Bar', 'Festa', 'Social']:\n",
        "            prob_perda += 0.25\n",
        "        elif contexto_uso in ['Parque', 'Carro']:\n",
        "            prob_perda += 0.15\n",
        "        elif contexto_uso in ['Trabalho']:\n",
        "            prob_perda += 0.10\n",
        "        # Casa mant√©m a probabilidade base\n",
        "\n",
        "        # Perfil do fumante (sociais e espor√°dicos perdem mais)\n",
        "        if perfil_fumante in ['Social', 'Esporadico']:\n",
        "            prob_perda += 0.15\n",
        "        elif perfil_fumante == 'Nao_fumante':\n",
        "            prob_perda += 0.10\n",
        "\n",
        "        # Tipo de isqueiro (descart√°veis s√£o perdidos mais facilmente)\n",
        "        if tipo_isqueiro == 'Descartavel':\n",
        "            prob_perda += 0.10\n",
        "\n",
        "        # Idade (jovens perdem mais)\n",
        "        if idade <= 25:\n",
        "            prob_perda += 0.10\n",
        "        elif idade <= 35:\n",
        "            prob_perda += 0.05\n",
        "\n",
        "        # Frequ√™ncia alta de uso (usa muito = leva para muitos lugares = maior risco)\n",
        "        if frequencia_uso > 3.0:\n",
        "            prob_perda += 0.10\n",
        "\n",
        "        # G√™nero (ajuste sutil baseado em padr√µes comportamentais)\n",
        "        if genero == 'M':\n",
        "            prob_perda += 0.05\n",
        "\n",
        "        # Limitar probabilidade entre 0 e 0.8 (m√°ximo 80% de chance)\n",
        "        prob_perda = min(0.8, max(0.05, prob_perda))\n",
        "\n",
        "        # Decidir se perdeu ou n√£o\n",
        "        perdeu = np.random.random() < prob_perda\n",
        "\n",
        "        # Se perdeu, definir data e local da perda\n",
        "        if perdeu:\n",
        "            dias_ate_perda = np.random.randint(1, tempo_posse + 1)\n",
        "            data_perda = data_compra + timedelta(days=dias_ate_perda)\n",
        "\n",
        "            # Local de perda baseado no contexto de uso\n",
        "            locais_perda = {\n",
        "                'Rua': ['Na_rua', 'Ponto_onibus', 'Calcada', 'Praca'],\n",
        "                'Bar': ['Bar', 'Restaurante', 'Balada', 'Mesa_bar'],\n",
        "                'Festa': ['Casa_amigo', 'Festa', 'Evento', 'Churrasco'],\n",
        "                'Social': ['Encontro_amigos', 'Social', 'Reuniao'],\n",
        "                'Trabalho': ['Escritorio', 'Trabalho', 'Cafeteria'],\n",
        "                'Parque': ['Parque', 'Praca', 'Area_verde'],\n",
        "                'Carro': ['Carro', 'Veiculo', 'Estacionamento'],\n",
        "                'Casa': ['Casa', 'Quarto', 'Cozinha', 'Sala']\n",
        "            }\n",
        "\n",
        "            local_perda = np.random.choice(locais_perda.get(contexto_uso, ['Desconhecido']))\n",
        "        else:\n",
        "            dias_ate_perda = 0\n",
        "            data_perda = None\n",
        "            local_perda = 'N/A'\n",
        "\n",
        "        # M√™s/ano para an√°lises temporais\n",
        "        mes_ano = data_uso.strftime('%Y-%m')\n",
        "\n",
        "        # Adicionar ao dataset\n",
        "        registro = {\n",
        "            'id_usuario': usuario_id,\n",
        "            'nome': nome,\n",
        "            'genero': genero,\n",
        "            'idade': idade,\n",
        "            'faixa_idade': faixa_idade,\n",
        "            'perfil_fumante': perfil_fumante,\n",
        "            'marca_isqueiro': marca,\n",
        "            'cor_isqueiro': cor,\n",
        "            'tipo_isqueiro': tipo_isqueiro,\n",
        "            'preco_compra': round(preco_compra, 2),\n",
        "            'data_compra': data_compra,\n",
        "            'data_uso': data_uso,\n",
        "            'tempo_posse': tempo_posse,\n",
        "            'contexto_uso': contexto_uso,\n",
        "            'proposito_uso': proposito_uso,\n",
        "            'num_ascendimentos': num_ascendimentos,\n",
        "            'frequencia_uso': round(frequencia_uso, 2),\n",
        "            'mes_ano': mes_ano,\n",
        "            'perdeu': perdeu,\n",
        "            'dias_ate_perda': dias_ate_perda,\n",
        "            'data_perda': data_perda,\n",
        "            'local_perda': local_perda\n",
        "        }\n",
        "\n",
        "        dados.append(registro)\n",
        "\n",
        "    # Criar DataFrame\n",
        "    df = pd.DataFrame(dados)\n",
        "\n",
        "    # Ajustar tipos de dados\n",
        "    df['data_compra'] = pd.to_datetime(df['data_compra'])\n",
        "    df['data_uso'] = pd.to_datetime(df['data_uso'])\n",
        "    df['data_perda'] = pd.to_datetime(df['data_perda'])\n",
        "    df['perdeu'] = df['perdeu'].astype(bool)\n",
        "\n",
        "    print(f\"‚úÖ Base sint√©tica gerada com sucesso!\")\n",
        "    print(f\"üìä Total de registros: {len(df)}\")\n",
        "    print(f\"üéØ Distribui√ß√£o da target:\")\n",
        "    print(f\"   - Perdidos: {df['perdeu'].sum()} ({df['perdeu'].mean()*100:.1f}%)\")\n",
        "    print(f\"   - N√£o perdidos: {(~df['perdeu']).sum()} ({(1-df['perdeu'].mean())*100:.1f}%)\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# Gerar a base de dados\n",
        "df = gerar_base_sintetica(n_registros=1200, seed=42)\n",
        "\n",
        "# Salvar a base bruta\n",
        "df.to_csv('lighter_tracker_dados_brutos.csv', index=False, encoding='utf-8')\n",
        "print(f\"\\nüíæ Base salva como 'lighter_tracker_dados_brutos.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABeUK-rsM8Q4",
        "outputId": "fb8c9dd6-ddda-42b5-deb8-dcc0ba339f58"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Gerando 1200 registros sint√©ticos...\n",
            "‚úÖ Base sint√©tica gerada com sucesso!\n",
            "üìä Total de registros: 1200\n",
            "üéØ Distribui√ß√£o da target:\n",
            "   - Perdidos: 606 (50.5%)\n",
            "   - N√£o perdidos: 594 (49.5%)\n",
            "\n",
            "üíæ Base salva como 'lighter_tracker_dados_brutos.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. AN√ÅLISE EXPLORAT√ìRIA DOS DADOS (EDA)"
      ],
      "metadata": {
        "id": "nL0SQXvQQSu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìä AN√ÅLISE EXPLORAT√ìRIA DOS DADOS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Informa√ß√µes gerais sobre a base\n",
        "print(\"\\nüîç INFORMA√á√ïES GERAIS DA BASE:\")\n",
        "print(f\"Dimens√µes: {df.shape}\")\n",
        "print(f\"Per√≠odo dos dados: {df['data_compra'].min().strftime('%Y-%m-%d')} a {df['data_uso'].max().strftime('%Y-%m-%d')}\")\n",
        "\n",
        "# Verificar valores nulos\n",
        "print(f\"\\nüîç VALORES NULOS:\")\n",
        "valores_nulos = df.isnull().sum()\n",
        "print(valores_nulos[valores_nulos > 0])\n",
        "\n",
        "# Estat√≠sticas descritivas das vari√°veis num√©ricas\n",
        "print(f\"\\nüîç ESTAT√çSTICAS DAS VARI√ÅVEIS NUM√âRICAS:\")\n",
        "print(df[['idade', 'preco_compra', 'tempo_posse', 'num_ascendimentos', 'frequencia_uso']].describe())\n",
        "\n",
        "# Distribui√ß√£o da vari√°vel target\n",
        "print(f\"\\nüéØ DISTRIBUI√á√ÉO DA VARI√ÅVEL TARGET (perdeu):\")\n",
        "target_dist = df['perdeu'].value_counts()\n",
        "print(target_dist)\n",
        "print(f\"Percentual de perdas: {df['perdeu'].mean()*100:.2f}%\")\n",
        "\n",
        "# An√°lise por contexto de uso\n",
        "print(f\"\\nüè¢ PERDAS POR CONTEXTO DE USO:\")\n",
        "perdas_contexto = df.groupby('contexto_uso')['perdeu'].agg(['count', 'sum', 'mean']).round(3)\n",
        "perdas_contexto.columns = ['Total', 'Perdidos', 'Taxa_Perda']\n",
        "perdas_contexto = perdas_contexto.sort_values('Taxa_Perda', ascending=False)\n",
        "print(perdas_contexto)\n",
        "\n",
        "# An√°lise por perfil de fumante\n",
        "print(f\"\\nüö¨ PERDAS POR PERFIL DE FUMANTE:\")\n",
        "perdas_perfil = df.groupby('perfil_fumante')['perdeu'].agg(['count', 'sum', 'mean']).round(3)\n",
        "perdas_perfil.columns = ['Total', 'Perdidos', 'Taxa_Perda']\n",
        "perdas_perfil = perdas_perfil.sort_values('Taxa_Perda', ascending=False)\n",
        "print(perdas_perfil)\n",
        "\n",
        "# An√°lise por marca\n",
        "print(f\"\\nüè∑Ô∏è PERDAS POR MARCA:\")\n",
        "perdas_marca = df.groupby('marca_isqueiro')['perdeu'].agg(['count', 'sum', 'mean']).round(3)\n",
        "perdas_marca.columns = ['Total', 'Perdidos', 'Taxa_Perda']\n",
        "perdas_marca = perdas_marca.sort_values('Taxa_Perda', ascending=False)\n",
        "print(perdas_marca)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGm_bjgaOPgr",
        "outputId": "95fd5a86-9fae-45f0-9fb2-9fdea6942f5b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "üìä AN√ÅLISE EXPLORAT√ìRIA DOS DADOS\n",
            "============================================================\n",
            "\n",
            "üîç INFORMA√á√ïES GERAIS DA BASE:\n",
            "Dimens√µes: (1200, 22)\n",
            "Per√≠odo dos dados: 2024-09-17 a 2026-02-22\n",
            "\n",
            "üîç VALORES NULOS:\n",
            "data_perda    594\n",
            "dtype: int64\n",
            "\n",
            "üîç ESTAT√çSTICAS DAS VARI√ÅVEIS NUM√âRICAS:\n",
            "             idade  preco_compra  tempo_posse  num_ascendimentos  \\\n",
            "count  1200.000000   1200.000000  1200.000000        1200.000000   \n",
            "mean     40.797500     12.428958    75.285833         120.417500   \n",
            "std      13.686402     16.904736    44.694822         102.153574   \n",
            "min      18.000000      0.520000     5.000000           1.000000   \n",
            "25%      29.000000      2.480000    40.000000          40.000000   \n",
            "50%      41.000000      3.690000    72.000000          96.000000   \n",
            "75%      52.000000      9.490000   103.000000         167.250000   \n",
            "max      64.000000     51.500000   199.000000         591.000000   \n",
            "\n",
            "       frequencia_uso  \n",
            "count     1200.000000  \n",
            "mean         1.585883  \n",
            "std          0.834748  \n",
            "min          0.080000  \n",
            "25%          0.890000  \n",
            "50%          1.520000  \n",
            "75%          2.040000  \n",
            "max          4.060000  \n",
            "\n",
            "üéØ DISTRIBUI√á√ÉO DA VARI√ÅVEL TARGET (perdeu):\n",
            "perdeu\n",
            "True     606\n",
            "False    594\n",
            "Name: count, dtype: int64\n",
            "Percentual de perdas: 50.50%\n",
            "\n",
            "üè¢ PERDAS POR CONTEXTO DE USO:\n",
            "              Total  Perdidos  Taxa_Perda\n",
            "contexto_uso                             \n",
            "Rua             178       118       0.663\n",
            "Bar             110        70       0.636\n",
            "Social           66        40       0.606\n",
            "Festa            34        20       0.588\n",
            "Parque          104        51       0.490\n",
            "Trabalho        229       103       0.450\n",
            "Carro            30        13       0.433\n",
            "Casa            449       191       0.425\n",
            "\n",
            "üö¨ PERDAS POR PERFIL DE FUMANTE:\n",
            "                Total  Perdidos  Taxa_Perda\n",
            "perfil_fumante                             \n",
            "Esporadico        233       132       0.567\n",
            "Pesado            185        98       0.530\n",
            "Nao_fumante       127        63       0.496\n",
            "Social            366       176       0.481\n",
            "Moderado          289       137       0.474\n",
            "\n",
            "üè∑Ô∏è PERDAS POR MARCA:\n",
            "                Total  Perdidos  Taxa_Perda\n",
            "marca_isqueiro                             \n",
            "Cricket           180       103       0.572\n",
            "Ronson            110        62       0.564\n",
            "Bic               439       226       0.515\n",
            "Clipper           231       113       0.489\n",
            "Zippo             188        81       0.431\n",
            "Generico           52        21       0.404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. PR√â-PROCESSAMENTO DOS DADOS PARA MACHINE LEARNING"
      ],
      "metadata": {
        "id": "Fl944xA-2U9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üîß PR√â-PROCESSAMENTO DOS DADOS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "def preparar_dados_ml(df):\n",
        "    \"\"\"\n",
        "    Prepara os dados para Machine Learning\n",
        "    - Seleciona features relevantes\n",
        "    - Trata valores categ√≥ricos\n",
        "    - Cria features derivadas\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"üîß Iniciando pr√©-processamento...\")\n",
        "\n",
        "    # Criar uma c√≥pia para n√£o modificar o original\n",
        "    df_ml = df.copy()\n",
        "\n",
        "    # Features que ser√£o utilizadas no modelo\n",
        "    features_numericas = [\n",
        "        'idade',\n",
        "        'preco_compra',\n",
        "        'tempo_posse',\n",
        "        'num_ascendimentos',\n",
        "        'frequencia_uso'\n",
        "    ]\n",
        "\n",
        "    features_categoricas = [\n",
        "        'genero',\n",
        "        'faixa_idade',\n",
        "        'perfil_fumante',\n",
        "        'marca_isqueiro',\n",
        "        'tipo_isqueiro',\n",
        "        'contexto_uso',\n",
        "        'proposito_uso'\n",
        "    ]\n",
        "\n",
        "    # Criar features derivadas\n",
        "    print(\"üîß Criando features derivadas...\")\n",
        "\n",
        "    # Feature: Intensidade de uso (ascendimentos por dia de posse)\n",
        "    df_ml['intensidade_uso'] = df_ml['num_ascendimentos'] / df_ml['tempo_posse']\n",
        "    df_ml['intensidade_uso'] = df_ml['intensidade_uso'].fillna(0)\n",
        "\n",
        "    # Feature: Categoria de pre√ßo\n",
        "    df_ml['categoria_preco'] = pd.cut(df_ml['preco_compra'],\n",
        "                                    bins=[0, 5, 15, 100],\n",
        "                                    labels=['Barato', 'Medio', 'Caro'])\n",
        "\n",
        "    # Feature: Categoria de idade\n",
        "    df_ml['categoria_idade'] = pd.cut(df_ml['idade'],\n",
        "                                    bins=[17, 25, 35, 50, 70],\n",
        "                                    labels=['Jovem', 'Adulto_Jovem', 'Adulto', 'Maduro'])\n",
        "\n",
        "    # Feature: M√™s da compra (sazonalidade)\n",
        "    df_ml['mes_compra'] = df_ml['data_compra'].dt.month\n",
        "\n",
        "    # Atualizar listas de features\n",
        "    features_numericas.extend(['intensidade_uso', 'mes_compra'])\n",
        "    features_categoricas.extend(['categoria_preco', 'categoria_idade'])\n",
        "\n",
        "    # Selecionar todas as features para o modelo\n",
        "    all_features = features_numericas + features_categoricas\n",
        "\n",
        "    print(f\"‚úÖ Features num√©ricas ({len(features_numericas)}): {features_numericas}\")\n",
        "    print(f\"‚úÖ Features categ√≥ricas ({len(features_categoricas)}): {features_categoricas}\")\n",
        "\n",
        "    return df_ml, all_features, features_numericas, features_categoricas\n",
        "\n",
        "# Preparar dados\n",
        "df_ml, all_features, features_numericas, features_categoricas = preparar_dados_ml(df)\n",
        "\n",
        "# Definir X e y\n",
        "X = df_ml[all_features]\n",
        "y = df_ml['perdeu']\n",
        "\n",
        "print(f\"\\nüéØ Dataset final para ML:\")\n",
        "print(f\"   - Shape: {X.shape}\")\n",
        "print(f\"   - Target distribution: {y.value_counts().to_dict()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2soC_1S2Ytp",
        "outputId": "9a5c4f93-231e-4dad-d4c9-e5e0fda0a05d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "üîß PR√â-PROCESSAMENTO DOS DADOS\n",
            "============================================================\n",
            "üîß Iniciando pr√©-processamento...\n",
            "üîß Criando features derivadas...\n",
            "‚úÖ Features num√©ricas (7): ['idade', 'preco_compra', 'tempo_posse', 'num_ascendimentos', 'frequencia_uso', 'intensidade_uso', 'mes_compra']\n",
            "‚úÖ Features categ√≥ricas (9): ['genero', 'faixa_idade', 'perfil_fumante', 'marca_isqueiro', 'tipo_isqueiro', 'contexto_uso', 'proposito_uso', 'categoria_preco', 'categoria_idade']\n",
            "\n",
            "üéØ Dataset final para ML:\n",
            "   - Shape: (1200, 16)\n",
            "   - Target distribution: {True: 606, False: 594}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. DIVIS√ÉO DOS DADOS (TREINO/TESTE)"
      ],
      "metadata": {
        "id": "x7PZV_9d31Az"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bibliotecas de Machine Learning"
      ],
      "metadata": {
        "id": "aIL6Qgz34blC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (classification_report, roc_auc_score, confusion_matrix,\n",
        "                           accuracy_score, precision_score, recall_score, f1_score, roc_curve)\n"
      ],
      "metadata": {
        "id": "LX3uJmXy4gBh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüîÄ Dividindo dados em treino e teste...\")\n",
        "\n",
        "# Divis√£o estratificada para manter propor√ß√£o da target\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,           # 20% para teste\n",
        "    stratify=y,              # Manter propor√ß√£o da target\n",
        "    random_state=42          # Reprodutibilidade\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Divis√£o conclu√≠da:\")\n",
        "print(f\"   - Treino: {X_train.shape[0]} amostras ({y_train.mean()*100:.1f}% perdas)\")\n",
        "print(f\"   - Teste: {X_test.shape[0]} amostras ({y_test.mean()*100:.1f}% perdas)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qhkTG1p30vO",
        "outputId": "509856af-96aa-49ba-8611-757925c94dd5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîÄ Dividindo dados em treino e teste...\n",
            "‚úÖ Divis√£o conclu√≠da:\n",
            "   - Treino: 960 amostras (50.5% perdas)\n",
            "   - Teste: 240 amostras (50.4% perdas)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. PIPELINE DE PR√â-PROCESSAMENTO"
      ],
      "metadata": {
        "id": "veHz6xpF4nBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\nüîß Criando pipeline de pr√©-processamento...\")\n",
        "\n",
        "# Definir transforma√ß√µes para cada tipo de vari√°vel\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        # Vari√°veis num√©ricas: padroniza√ß√£o (m√©dia=0, desvio=1)\n",
        "        ('num', StandardScaler(), features_numericas),\n",
        "\n",
        "        # Vari√°veis categ√≥ricas: One-Hot Encoding\n",
        "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), features_categoricas)\n",
        "    ],\n",
        "    remainder='drop'  # Descartar colunas n√£o especificadas\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Pipeline de pr√©-processamento criado:\")\n",
        "print(f\"   - Padroniza√ß√£o para: {features_numericas}\")\n",
        "print(f\"   - One-Hot Encoding para: {features_categoricas}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AL8Vj-ye30Mv",
        "outputId": "ae29c14f-d3a7-4cd8-b4e1-a7a8d520a28b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîß Criando pipeline de pr√©-processamento...\n",
            "‚úÖ Pipeline de pr√©-processamento criado:\n",
            "   - Padroniza√ß√£o para: ['idade', 'preco_compra', 'tempo_posse', 'num_ascendimentos', 'frequencia_uso', 'intensidade_uso', 'mes_compra']\n",
            "   - One-Hot Encoding para: ['genero', 'faixa_idade', 'perfil_fumante', 'marca_isqueiro', 'tipo_isqueiro', 'contexto_uso', 'proposito_uso', 'categoria_preco', 'categoria_idade']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. MODELO DE REGRESS√ÉO LOG√çSTICA\n"
      ],
      "metadata": {
        "id": "ZXAh4f0n4pv4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ü§ñ TREINAMENTO DO MODELO DE REGRESS√ÉO LOG√çSTICA\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Criar pipeline completo (pr√©-processamento + modelo)\n",
        "pipeline_lr = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', LogisticRegression(\n",
        "        class_weight='balanced',    # Lidar com desbalanceamento\n",
        "        random_state=42,           # Reprodutibilidade\n",
        "        max_iter=1000             # Evitar warnings de converg√™ncia\n",
        "    ))\n",
        "])\n",
        "\n",
        "print(\"ü§ñ Pipeline criado com:\")\n",
        "print(\"   - Pr√©-processamento autom√°tico\")\n",
        "print(\"   - Regress√£o Log√≠stica com class_weight='balanced'\")\n",
        "print(\"   - Tratamento autom√°tico de desbalanceamento\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DO7Wp3WD4r-H",
        "outputId": "8e04413d-bb2b-4c2b-ac38-8e893e92166b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "ü§ñ TREINAMENTO DO MODELO DE REGRESS√ÉO LOG√çSTICA\n",
            "============================================================\n",
            "ü§ñ Pipeline criado com:\n",
            "   - Pr√©-processamento autom√°tico\n",
            "   - Regress√£o Log√≠stica com class_weight='balanced'\n",
            "   - Tratamento autom√°tico de desbalanceamento\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. OTIMIZA√á√ÉO DE HIPERPAR√ÇMETROS"
      ],
      "metadata": {
        "id": "Ipl2xewU4xa-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\nüéØ Otimizando hiperpar√¢metros com GridSearchCV...\")\n",
        "\n",
        "# Definir grade de hiperpar√¢metros para testar\n",
        "param_grid = {\n",
        "    'classifier__C': [0.01, 0.1, 1, 10, 100],           # For√ßa da regulariza√ß√£o\n",
        "    'classifier__penalty': ['l1', 'l2'],                 # Tipo de regulariza√ß√£o\n",
        "    'classifier__solver': ['liblinear', 'saga']          # Algoritmo de otimiza√ß√£o\n",
        "}\n",
        "\n",
        "# GridSearchCV com valida√ß√£o cruzada\n",
        "grid_search = GridSearchCV(\n",
        "    pipeline_lr,\n",
        "    param_grid,\n",
        "    cv=5,                      # 5-fold cross-validation\n",
        "    scoring='f1',              # M√©trica para otimiza√ß√£o (boa para desbalanceamento)\n",
        "    n_jobs=-1,                 # Usar todos os cores\n",
        "    verbose=1                  # Mostrar progresso\n",
        ")\n",
        "\n",
        "# Treinar com otimiza√ß√£o\n",
        "print(\"‚è≥ Treinando modelo com diferentes combina√ß√µes de hiperpar√¢metros...\")\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Melhor modelo encontrado\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "print(f\"\\n‚úÖ Otimiza√ß√£o conclu√≠da!\")\n",
        "print(f\"üèÜ Melhores hiperpar√¢metros: {grid_search.best_params_}\")\n",
        "print(f\"üìä Melhor F1-Score (CV): {grid_search.best_score_:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTRRRurS4xHr",
        "outputId": "badba320-8f20-4311-ae44-19c5f4021e3d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üéØ Otimizando hiperpar√¢metros com GridSearchCV...\n",
            "‚è≥ Treinando modelo com diferentes combina√ß√µes de hiperpar√¢metros...\n",
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "\n",
            "‚úÖ Otimiza√ß√£o conclu√≠da!\n",
            "üèÜ Melhores hiperpar√¢metros: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}\n",
            "üìä Melhor F1-Score (CV): 0.5665\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. AVALIA√á√ÉO DO MODELO"
      ],
      "metadata": {
        "id": "at2Kckw45AcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìä AVALIA√á√ÉO DO MODELO\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Fazer predi√ß√µes no conjunto de teste\n",
        "y_pred = best_model.predict(X_test)\n",
        "y_pred_proba = best_model.predict_proba(X_test)[:, 1]  # Probabilidades da classe positiva\n",
        "\n",
        "# Calcular m√©tricas\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "print(\"üéØ M√âTRICAS DE AVALIA√á√ÉO:\")\n",
        "print(f\"   - Acur√°cia:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "print(f\"   - Precis√£o:  {precision:.4f} ({precision*100:.2f}%)\")\n",
        "print(f\"   - Recall:    {recall:.4f} ({recall*100:.2f}%)\")\n",
        "print(f\"   - F1-Score:  {f1:.4f} ({f1*100:.2f}%)\")\n",
        "print(f\"   - AUC-ROC:   {auc_roc:.4f} ({auc_roc*100:.2f}%)\")\n",
        "\n",
        "print(f\"\\nüìã RELAT√ìRIO DETALHADO:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['N√£o Perdeu', 'Perdeu']))\n",
        "\n",
        "print(f\"\\nüîç MATRIZ DE CONFUS√ÉO:\")\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(f\"                 Predito\")\n",
        "print(f\"              N√£o  |  Sim\")\n",
        "print(f\"Real N√£o  [{cm[0,0]:4d}  |  {cm[0,1]:3d}]\")\n",
        "print(f\"     Sim  [{cm[1,0]:4d}  |  {cm[1,1]:3d}]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5RPAtFa4vqS",
        "outputId": "e5efc644-2a32-4bfd-c78d-e8ec5f78f603"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "üìä AVALIA√á√ÉO DO MODELO\n",
            "============================================================\n",
            "üéØ M√âTRICAS DE AVALIA√á√ÉO:\n",
            "   - Acur√°cia:  0.5833 (58.33%)\n",
            "   - Precis√£o:  0.5882 (58.82%)\n",
            "   - Recall:    0.5785 (57.85%)\n",
            "   - F1-Score:  0.5833 (58.33%)\n",
            "   - AUC-ROC:   0.6222 (62.22%)\n",
            "\n",
            "üìã RELAT√ìRIO DETALHADO:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  N√£o Perdeu       0.58      0.59      0.58       119\n",
            "      Perdeu       0.59      0.58      0.58       121\n",
            "\n",
            "    accuracy                           0.58       240\n",
            "   macro avg       0.58      0.58      0.58       240\n",
            "weighted avg       0.58      0.58      0.58       240\n",
            "\n",
            "\n",
            "üîç MATRIZ DE CONFUS√ÉO:\n",
            "                 Predito\n",
            "              N√£o  |  Sim\n",
            "Real N√£o  [  70  |   49]\n",
            "     Sim  [  51  |   70]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. INTERPRETA√á√ÉO DO MODELO (FEATURE IMPORTANCE)"
      ],
      "metadata": {
        "id": "eLhqPvWZ5Jsx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üîç INTERPRETA√á√ÉO DO MODELO\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Obter nomes das features ap√≥s pr√©-processamento\n",
        "feature_names = (\n",
        "    features_numericas +\n",
        "    list(best_model.named_steps['preprocessor']\n",
        "         .named_transformers_['cat']\n",
        "         .get_feature_names_out(features_categoricas))\n",
        ")\n",
        "\n",
        "# Obter coeficientes do modelo\n",
        "coeficientes = best_model.named_steps['classifier'].coef_[0]\n",
        "\n",
        "# Criar DataFrame com feature importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Coeficiente': coeficientes,\n",
        "    'Importancia_Abs': np.abs(coeficientes)\n",
        "}).sort_values('Importancia_Abs', ascending=False)\n",
        "\n",
        "print(\"üîç TOP 15 FEATURES MAIS IMPORTANTES:\")\n",
        "print(\"(Coeficientes positivos aumentam probabilidade de perda)\")\n",
        "print(\"(Coeficientes negativos diminuem probabilidade de perda)\")\n",
        "print(\"-\" * 60)\n",
        "for idx, row in feature_importance.head(15).iterrows():\n",
        "    sinal = \"‚Üë\" if row['Coeficiente'] > 0 else \"‚Üì\"\n",
        "    print(f\"{sinal} {row['Feature']:<35} | {row['Coeficiente']:>8.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txFg6BCD5LYu",
        "outputId": "85a92af1-0b38-441a-abc9-821f153c61ac"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "üîç INTERPRETA√á√ÉO DO MODELO\n",
            "============================================================\n",
            "üîç TOP 15 FEATURES MAIS IMPORTANTES:\n",
            "(Coeficientes positivos aumentam probabilidade de perda)\n",
            "(Coeficientes negativos diminuem probabilidade de perda)\n",
            "------------------------------------------------------------\n",
            "‚Üì marca_isqueiro_Zippo                |  -1.1393\n",
            "‚Üì contexto_uso_Casa                   |  -1.0691\n",
            "‚Üì contexto_uso_Trabalho               |  -1.0142\n",
            "‚Üì contexto_uso_Carro                  |  -0.9783\n",
            "‚Üì perfil_fumante_Pesado               |  -0.9483\n",
            "‚Üì perfil_fumante_Moderado             |  -0.8240\n",
            "‚Üì contexto_uso_Parque                 |  -0.6839\n",
            "‚Üì proposito_uso_Charuto               |  -0.6680\n",
            "‚Üì categoria_preco_Medio               |  -0.6534\n",
            "‚Üì perfil_fumante_Social               |  -0.6162\n",
            "‚Üì marca_isqueiro_Generico             |  -0.6098\n",
            "‚Üë marca_isqueiro_Clipper              |   0.5646\n",
            "‚Üì proposito_uso_Incenso               |  -0.5624\n",
            "‚Üë categoria_idade_Jovem               |   0.5301\n",
            "‚Üì proposito_uso_Tabaco                |  -0.4554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. VALIDA√á√ÉO CRUZADA COMPLETA"
      ],
      "metadata": {
        "id": "lyn4zIOn5Q4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\nüîÑ Valida√ß√£o cruzada completa (5-fold)...\")\n",
        "\n",
        "# Valida√ß√£o cruzada com m√∫ltiplas m√©tricas\n",
        "scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
        "cv_results = {}\n",
        "\n",
        "for score in scoring:\n",
        "    scores = cross_val_score(best_model, X, y, cv=5, scoring=score, n_jobs=-1)\n",
        "    cv_results[score] = {\n",
        "        'mean': scores.mean(),\n",
        "        'std': scores.std(),\n",
        "        'scores': scores\n",
        "    }\n",
        "\n",
        "print(\"üìä RESULTADOS DA VALIDA√á√ÉO CRUZADA (5-fold):\")\n",
        "for metric, results in cv_results.items():\n",
        "    print(f\"   - {metric.upper():<12}: {results['mean']:.4f} (¬±{results['std']:.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7V1cDpxS5Szm",
        "outputId": "aad80b7d-5dab-4878-f9ce-2bfc957e1cae"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîÑ Valida√ß√£o cruzada completa (5-fold)...\n",
            "üìä RESULTADOS DA VALIDA√á√ÉO CRUZADA (5-fold):\n",
            "   - ACCURACY    : 0.5767 (¬±0.0341)\n",
            "   - PRECISION   : 0.5843 (¬±0.0359)\n",
            "   - RECALL      : 0.5694 (¬±0.0346)\n",
            "   - F1          : 0.5761 (¬±0.0289)\n",
            "   - ROC_AUC     : 0.6082 (¬±0.0403)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12. PREDI√á√ïES NA BASE COMPLETA"
      ],
      "metadata": {
        "id": "NQpZPI8_5XIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\nüîÆ Gerando predi√ß√µes para toda a base...\")\n",
        "\n",
        "# Fazer predi√ß√µes para toda a base de dados\n",
        "X_full = df_ml[all_features]\n",
        "y_full = df_ml['perdeu']\n",
        "\n",
        "probabilidades_completas = best_model.predict_proba(X_full)[:, 1]\n",
        "predicoes_completas = best_model.predict(X_full)\n",
        "\n",
        "# Adicionar predi√ß√µes ao DataFrame original\n",
        "df_final = df_ml.copy()\n",
        "df_final['probabilidade_perda'] = probabilidades_completas\n",
        "df_final['predicao_perda'] = predicoes_completas\n",
        "df_final['acerto_modelo'] = (df_final['predicao_perda'] == df_final['perdeu'])\n",
        "\n",
        "print(f\"‚úÖ Predi√ß√µes geradas para {len(df_final)} registros\")\n",
        "print(f\"üìä Acur√°cia geral: {df_final['acerto_modelo'].mean()*100:.2f}%\")\n",
        "\n",
        "# Salvar base com predi√ß√µes\n",
        "df_final.to_csv('lighter_tracker_com_predicoes.csv', index=False, encoding='utf-8')\n",
        "print(\"üíæ Base com predi√ß√µes salva como 'lighter_tracker_com_predicoes.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TF4GkAZE5aMd",
        "outputId": "3ed5e45f-06ba-4345-cf77-e7d44b3dd89d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîÆ Gerando predi√ß√µes para toda a base...\n",
            "‚úÖ Predi√ß√µes geradas para 1200 registros\n",
            "üìä Acur√°cia geral: 60.83%\n",
            "üíæ Base com predi√ß√µes salva como 'lighter_tracker_com_predicoes.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 13. AN√ÅLISE DE CASOS EXTREMOS"
      ],
      "metadata": {
        "id": "WjEgKIHB5eIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\nüîç Analisando casos extremos...\")\n",
        "\n",
        "# Casos com maior probabilidade de perda\n",
        "print(\"üî¥ TOP 5 CASOS COM MAIOR RISCO DE PERDA:\")\n",
        "top_risco = df_final.nlargest(5, 'probabilidade_perda')[\n",
        "    ['nome', 'contexto_uso', 'proposito_uso', 'perfil_fumante',\n",
        "     'marca_isqueiro', 'probabilidade_perda', 'perdeu']\n",
        "]\n",
        "print(top_risco.to_string(index=False))\n",
        "\n",
        "# Casos com menor probabilidade de perda\n",
        "print(\"\\nüü¢ TOP 5 CASOS COM MENOR RISCO DE PERDA:\")\n",
        "baixo_risco = df_final.nsmallest(5, 'probabilidade_perda')[\n",
        "    ['nome', 'contexto_uso', 'proposito_uso', 'perfil_fumante',\n",
        "     'marca_isqueiro', 'probabilidade_perda', 'perdeu']\n",
        "]\n",
        "print(baixo_risco.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LNJE7su5gL-",
        "outputId": "9ac7e64a-a5bf-457a-da31-3ffe58742733"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç Analisando casos extremos...\n",
            "üî¥ TOP 5 CASOS COM MAIOR RISCO DE PERDA:\n",
            "        nome contexto_uso proposito_uso perfil_fumante marca_isqueiro  probabilidade_perda  perdeu\n",
            "Usuario_1128          Bar         Fogao     Esporadico         Ronson             0.935948    True\n",
            " Usuario_935          Rua          Vela     Esporadico         Ronson             0.872025    True\n",
            " Usuario_396          Rua         Fogao         Social         Ronson             0.869770    True\n",
            " Usuario_650          Rua       Cigarro     Esporadico         Ronson             0.858746    True\n",
            " Usuario_925          Rua          Vela     Esporadico            Bic             0.852782    True\n",
            "\n",
            "üü¢ TOP 5 CASOS COM MENOR RISCO DE PERDA:\n",
            "        nome contexto_uso proposito_uso perfil_fumante marca_isqueiro  probabilidade_perda  perdeu\n",
            "Usuario_1145         Casa        Tabaco    Nao_fumante          Zippo             0.188125   False\n",
            "Usuario_1069         Casa       Incenso       Moderado       Generico             0.192565   False\n",
            " Usuario_715         Casa        Tabaco       Moderado       Generico             0.199628   False\n",
            " Usuario_153     Trabalho        Tabaco         Pesado       Generico             0.203596   False\n",
            " Usuario_207         Casa        Tabaco       Moderado       Generico             0.204106   False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 14. PREPARA√á√ÉO PARA DEPLOY"
      ],
      "metadata": {
        "id": "DYZLwT8e5iuz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Para deploy do modelo\n"
      ],
      "metadata": {
        "id": "2dtVsgeK5jjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import joblib\n",
        "import json\n"
      ],
      "metadata": {
        "id": "VbSsYdIh5nFD"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üöÄ PREPARA√á√ÉO PARA DEPLOY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Salvar o modelo treinado\n",
        "model_filename = 'lighter_tracker_model.pkl'\n",
        "joblib.dump(best_model, model_filename)\n",
        "print(f\"üíæ Modelo salvo como '{model_filename}'\")\n",
        "\n",
        "# Salvar informa√ß√µes do modelo\n",
        "model_info = {\n",
        "    'model_type': 'Logistic Regression',\n",
        "    'features': all_features,\n",
        "    'features_numericas': features_numericas,\n",
        "    'features_categoricas': features_categoricas,\n",
        "    'target': 'perdeu',\n",
        "    'accuracy': accuracy,\n",
        "    'precision': precision,\n",
        "    'recall': recall,\n",
        "    'f1_score': f1,\n",
        "    'auc_roc': auc_roc,\n",
        "    'best_params': grid_search.best_params_,\n",
        "    'cv_f1_mean': cv_results['f1']['mean'],\n",
        "    'training_date': datetime.now().isoformat(),\n",
        "    'total_samples': len(df_final),\n",
        "    'positive_class_ratio': y.mean()\n",
        "}\n",
        "\n",
        "with open('model_info.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(model_info, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(\"üíæ Informa√ß√µes do modelo salvas como 'model_info.json'\")\n",
        "\n",
        "# Criar fun√ß√£o para predi√ß√£o em produ√ß√£o\n",
        "def criar_funcao_predicao():\n",
        "    \"\"\"\n",
        "    Cria fun√ß√£o para ser usada em produ√ß√£o\n",
        "    \"\"\"\n",
        "    codigo_producao = '''\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def carregar_modelo():\n",
        "    \"\"\"Carrega o modelo treinado\"\"\"\n",
        "    try:\n",
        "        model = joblib.load('lighter_tracker_model.pkl')\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"Erro ao carregar modelo: {e}\")\n",
        "\n",
        "def preparar_entrada(dados_usuario):\n",
        "    \"\"\"\n",
        "    Prepara os dados de entrada para predi√ß√£o\n",
        "\n",
        "    Par√¢metros esperados no dicion√°rio dados_usuario:\n",
        "    - genero: 'M' ou 'F'\n",
        "    - idade: int (18-65)\n",
        "    - perfil_fumante: 'Pesado', 'Moderado', 'Social', 'Esporadico', 'Nao_fumante'\n",
        "    - marca_isqueiro: 'Bic', 'Zippo', 'Clipper', 'Cricket', 'Ronson', 'Generico'\n",
        "    - tipo_isqueiro: 'Descartavel' ou 'Recarregavel'\n",
        "    - preco_compra: float (0.5-100.0)\n",
        "    - tempo_posse: int (dias)\n",
        "    - contexto_uso: 'Casa', 'Rua', 'Trabalho', 'Bar', 'Parque', 'Social', 'Festa', 'Carro'\n",
        "    - proposito_uso: 'Cigarro', 'Tabaco', 'Vela', 'Incenso', 'Fogao', 'Camping', 'Charuto', 'Outro'\n",
        "    - num_ascendimentos: int\n",
        "    - frequencia_uso: float (ascendimentos por dia)\n",
        "    \"\"\"\n",
        "\n",
        "    # Criar features derivadas\n",
        "    intensidade_uso = dados_usuario['num_ascendimentos'] / max(dados_usuario['tempo_posse'], 1)\n",
        "\n",
        "    # Categoria de pre√ßo\n",
        "    if dados_usuario['preco_compra'] <= 5:\n",
        "        categoria_preco = 'Barato'\n",
        "    elif dados_usuario['preco_compra'] <= 15:\n",
        "        categoria_preco = 'Medio'\n",
        "    else:\n",
        "        categoria_preco = 'Caro'\n",
        "\n",
        "    # Categoria de idade\n",
        "    idade = dados_usuario['idade']\n",
        "    if idade <= 25:\n",
        "        categoria_idade = 'Jovem'\n",
        "    elif idade <= 35:\n",
        "        categoria_idade = 'Adulto_Jovem'\n",
        "    elif idade <= 50:\n",
        "        categoria_idade = 'Adulto'\n",
        "    else:\n",
        "        categoria_idade = 'Maduro'\n",
        "\n",
        "    # Faixa et√°ria\n",
        "    if idade <= 25:\n",
        "        faixa_idade = '18-25'\n",
        "    elif idade <= 35:\n",
        "        faixa_idade = '26-35'\n",
        "    elif idade <= 50:\n",
        "        faixa_idade = '36-50'\n",
        "    else:\n",
        "        faixa_idade = '51+'\n",
        "\n",
        "    # M√™s atual\n",
        "    mes_compra = datetime.now().month\n",
        "\n",
        "    # Criar DataFrame com todas as features necess√°rias\n",
        "    features_dict = {\n",
        "        'idade': dados_usuario['idade'],\n",
        "        'preco_compra': dados_usuario['preco_compra'],\n",
        "        'tempo_posse': dados_usuario['tempo_posse'],\n",
        "        'num_ascendimentos': dados_usuario['num_ascendimentos'],\n",
        "        'frequencia_uso': dados_usuario['frequencia_uso'],\n",
        "        'intensidade_uso': intensidade_uso,\n",
        "        'mes_compra': mes_compra,\n",
        "        'genero': dados_usuario['genero'],\n",
        "        'faixa_idade': faixa_idade,\n",
        "        'perfil_fumante': dados_usuario['perfil_fumante'],\n",
        "        'marca_isqueiro': dados_usuario['marca_isqueiro'],\n",
        "        'tipo_isqueiro': dados_usuario['tipo_isqueiro'],\n",
        "        'contexto_uso': dados_usuario['contexto_uso'],\n",
        "        'proposito_uso': dados_usuario['proposito_uso'],\n",
        "        'categoria_preco': categoria_preco,\n",
        "        'categoria_idade': categoria_idade\n",
        "    }\n",
        "\n",
        "    return pd.DataFrame([features_dict])\n",
        "\n",
        "def prever_perda_isqueiro(dados_usuario):\n",
        "    \"\"\"\n",
        "    Fun√ß√£o principal para prever perda de isqueiro\n",
        "\n",
        "    Retorna:\n",
        "    - probabilidade: float (0-1) - Probabilidade de perda\n",
        "    - categoria_risco: str - Categoria do risco\n",
        "    - recomendacao: str - Recomenda√ß√£o para o usu√°rio\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        # Carregar modelo\n",
        "        model = carregar_modelo()\n",
        "\n",
        "        # Preparar dados\n",
        "        df_input = preparar_entrada(dados_usuario)\n",
        "\n",
        "        # Fazer predi√ß√£o\n",
        "        probabilidade = model.predict_proba(df_input)[0, 1]\n",
        "        predicao = model.predict(df_input)[0]\n",
        "\n",
        "        # Categorizar risco\n",
        "        if probabilidade < 0.3:\n",
        "            categoria_risco = \"Baixo\"\n",
        "            emoji_risco = \"üü¢\"\n",
        "        elif probabilidade < 0.6:\n",
        "            categoria_risco = \"M√©dio\"\n",
        "            emoji_risco = \"üü°\"\n",
        "        else:\n",
        "            categoria_risco = \"Alto\"\n",
        "            emoji_risco = \"üî¥\"\n",
        "\n",
        "        # Gerar recomenda√ß√µes baseadas nos fatores de risco\n",
        "        recomendacoes = []\n",
        "\n",
        "        if dados_usuario['contexto_uso'] in ['Rua', 'Bar', 'Festa', 'Social']:\n",
        "            recomendacoes.append(\"‚ö†Ô∏è Evite levar seu isqueiro para locais p√∫blicos se poss√≠vel\")\n",
        "\n",
        "        if dados_usuario['perfil_fumante'] in ['Social', 'Esporadico']:\n",
        "            recomendacoes.append(\"üí° Considere manter seu isqueiro sempre no mesmo bolso\")\n",
        "\n",
        "        if dados_usuario['tipo_isqueiro'] == 'Descartavel':\n",
        "            recomendacoes.append(\"üîÑ Isqueiros descart√°veis s√£o perdidos mais facilmente - considere um recarreg√°vel\")\n",
        "\n",
        "        if dados_usuario['frequencia_uso'] > 3.0:\n",
        "            recomendacoes.append(\"üì± Alto uso = alto risco. Configure lembretes para verificar seu isqueiro\")\n",
        "\n",
        "        if dados_usuario['idade'] <= 25:\n",
        "            recomendacoes.append(\"üë§ Jovens tendem a perder mais - tenha aten√ß√£o extra!\")\n",
        "\n",
        "        if not recomendacoes:\n",
        "            recomendacoes.append(\"‚úÖ Continue com seus h√°bitos atuais - baixo risco de perda!\")\n",
        "\n",
        "        resultado = {\n",
        "            'probabilidade': round(probabilidade * 100, 2),\n",
        "            'categoria_risco': categoria_risco,\n",
        "            'emoji_risco': emoji_risco,\n",
        "            'predicao_binaria': 'Sim' if predicao else 'N√£o',\n",
        "            'recomendacoes': recomendacoes,\n",
        "            'fatores_risco': {\n",
        "                'contexto_uso': dados_usuario['contexto_uso'],\n",
        "                'perfil_fumante': dados_usuario['perfil_fumante'],\n",
        "                'tipo_isqueiro': dados_usuario['tipo_isqueiro'],\n",
        "                'frequencia_uso': dados_usuario['frequencia_uso'],\n",
        "                'idade': dados_usuario['idade']\n",
        "            }\n",
        "        }\n",
        "\n",
        "        return resultado\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            'erro': f\"Erro na predi√ß√£o: {str(e)}\",\n",
        "            'probabilidade': None,\n",
        "            'categoria_risco': None,\n",
        "            'recomendacao': \"Erro no processamento\"\n",
        "        }\n",
        "\n",
        "# EXEMPLO DE USO:\n",
        "if __name__ == \"__main__\":\n",
        "    # Exemplo 1: Alto risco\n",
        "    exemplo_alto_risco = {\n",
        "        'genero': 'M',\n",
        "        'idade': 22,\n",
        "        'perfil_fumante': 'Social',\n",
        "        'marca_isqueiro': 'Bic',\n",
        "        'tipo_isqueiro': 'Descartavel',\n",
        "        'preco_compra': 2.50,\n",
        "        'tempo_posse': 15,\n",
        "        'contexto_uso': 'Bar',\n",
        "        'proposito_uso': 'Cigarro',\n",
        "        'num_ascendimentos': 50,\n",
        "        'frequencia_uso': 3.33\n",
        "    }\n",
        "\n",
        "    # Exemplo 2: Baixo risco\n",
        "    exemplo_baixo_risco = {\n",
        "        'genero': 'F',\n",
        "        'idade': 45,\n",
        "        'perfil_fumante': 'Nao_fumante',\n",
        "        'marca_isqueiro': 'Zippo',\n",
        "        'tipo_isqueiro': 'Recarregavel',\n",
        "        'preco_compra': 55.00,\n",
        "        'tempo_posse': 90,\n",
        "        'contexto_uso': 'Casa',\n",
        "        'proposito_uso': 'Vela',\n",
        "        'num_ascendimentos': 25,\n",
        "        'frequencia_uso': 0.28\n",
        "    }\n",
        "\n",
        "    print(\"=== TESTE DO MODELO ===\")\n",
        "    print(\"\\\\nüî¥ EXEMPLO ALTO RISCO:\")\n",
        "    resultado1 = prever_perda_isqueiro(exemplo_alto_risco)\n",
        "    print(f\"Probabilidade: {resultado1['probabilidade']:.1f}%\")\n",
        "    print(f\"Categoria: {resultado1['emoji_risco']} {resultado1['categoria_risco']}\")\n",
        "    print(\"Recomenda√ß√µes:\")\n",
        "    for rec in resultado1['recomendacoes']:\n",
        "        print(f\"  {rec}\")\n",
        "\n",
        "    print(\"\\\\nüü¢ EXEMPLO BAIXO RISCO:\")\n",
        "    resultado2 = prever_perda_isqueiro(exemplo_baixo_risco)\n",
        "    print(f\"Probabilidade: {resultado2['probabilidade']:.1f}%\")\n",
        "    print(f\"Categoria: {resultado2['emoji_risco']} {resultado2['categoria_risco']}\")\n",
        "    print(\"Recomenda√ß√µes:\")\n",
        "    for rec in resultado2['recomendacoes']:\n",
        "        print(f\"  {rec}\")\n",
        "'''\n",
        "\n",
        "    return codigo_producao\n",
        "\n",
        "# Salvar c√≥digo de produ√ß√£o\n",
        "codigo_producao = criar_funcao_predicao()\n",
        "with open('lighter_tracker_predicao.py', 'w', encoding='utf-8') as f:\n",
        "    f.write(codigo_producao)\n",
        "\n",
        "print(\"üíæ C√≥digo para produ√ß√£o salvo como 'lighter_tracker_predicao.py'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgROIpVU5y_S",
        "outputId": "965fcc7a-b999-4e6d-d2d9-9aa3205684d3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "üöÄ PREPARA√á√ÉO PARA DEPLOY\n",
            "============================================================\n",
            "üíæ Modelo salvo como 'lighter_tracker_model.pkl'\n",
            "üíæ Informa√ß√µes do modelo salvas como 'model_info.json'\n",
            "üíæ C√≥digo para produ√ß√£o salvo como 'lighter_tracker_predicao.py'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 15. TESTE DA FUN√á√ÉO DE PRODU√á√ÉO"
      ],
      "metadata": {
        "id": "l9ljKNrp52su"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\nüß™ Testando fun√ß√£o de produ√ß√£o...\")\n",
        "\n",
        "# Simular exemplos para teste\n",
        "exemplo_alto_risco = {\n",
        "    'genero': 'M',\n",
        "    'idade': 22,\n",
        "    'perfil_fumante': 'Social',\n",
        "    'marca_isqueiro': 'Bic',\n",
        "    'tipo_isqueiro': 'Descartavel',\n",
        "    'preco_compra': 2.50,\n",
        "    'tempo_posse': 15,\n",
        "    'contexto_uso': 'Bar',\n",
        "    'proposito_uso': 'Cigarro',\n",
        "    'num_ascendimentos': 50,\n",
        "    'frequencia_uso': 3.33\n",
        "}\n",
        "\n",
        "exemplo_baixo_risco = {\n",
        "    'genero': 'F',\n",
        "    'idade': 45,\n",
        "    'perfil_fumante': 'Nao_fumante',\n",
        "    'marca_isqueiro': 'Zippo',\n",
        "    'tipo_isqueiro': 'Recarregavel',\n",
        "    'preco_compra': 55.00,\n",
        "    'tempo_posse': 90,\n",
        "    'contexto_uso': 'Casa',\n",
        "    'proposito_uso': 'Vela',\n",
        "    'num_ascendimentos': 25,\n",
        "    'frequencia_uso': 0.28\n",
        "}\n",
        "\n",
        "# Fun√ß√£o de teste (simula√ß√£o da fun√ß√£o de produ√ß√£o)\n",
        "def testar_predicao(dados_usuario, nome_caso):\n",
        "    \"\"\"Testa a predi√ß√£o com os dados fornecidos\"\"\"\n",
        "\n",
        "    # Preparar dados igual √† fun√ß√£o de produ√ß√£o\n",
        "    df_test = pd.DataFrame([dados_usuario])\n",
        "\n",
        "    # Criar features derivadas\n",
        "    df_test['intensidade_uso'] = df_test['num_ascendimentos'] / df_test['tempo_posse']\n",
        "\n",
        "    # Categorias\n",
        "    df_test['categoria_preco'] = pd.cut(df_test['preco_compra'],\n",
        "                                       bins=[0, 5, 15, 100],\n",
        "                                       labels=['Barato', 'Medio', 'Caro'])\n",
        "\n",
        "    df_test['categoria_idade'] = pd.cut(df_test['idade'],\n",
        "                                       bins=[17, 25, 35, 50, 70],\n",
        "                                       labels=['Jovem', 'Adulto_Jovem', 'Adulto', 'Maduro'])\n",
        "\n",
        "    # Faixa et√°ria\n",
        "    idade = df_test['idade'].iloc[0]\n",
        "    if idade <= 25:\n",
        "        faixa_idade = '18-25'\n",
        "    elif idade <= 35:\n",
        "        faixa_idade = '26-35'\n",
        "    elif idade <= 50:\n",
        "        faixa_idade = '36-50'\n",
        "    else:\n",
        "        faixa_idade = '51+'\n",
        "\n",
        "    df_test['faixa_idade'] = faixa_idade\n",
        "    df_test['mes_compra'] = datetime.now().month\n",
        "\n",
        "    # Selecionar features na ordem correta\n",
        "    df_test = df_test[all_features]\n",
        "\n",
        "    # Fazer predi√ß√£o\n",
        "    probabilidade = best_model.predict_proba(df_test)[0, 1]\n",
        "\n",
        "    # Categorizar risco\n",
        "    if probabilidade < 0.3:\n",
        "        categoria_risco = \"Baixo üü¢\"\n",
        "    elif probabilidade < 0.6:\n",
        "        categoria_risco = \"M√©dio üü°\"\n",
        "    else:\n",
        "        categoria_risco = \"Alto üî¥\"\n",
        "\n",
        "    print(f\"\\n{nome_caso}:\")\n",
        "    print(f\"  Probabilidade de perda: {probabilidade*100:.1f}%\")\n",
        "    print(f\"  Categoria de risco: {categoria_risco}\")\n",
        "\n",
        "    return probabilidade\n",
        "\n",
        "# Testar exemplos\n",
        "prob_alto = testar_predicao(exemplo_alto_risco, \"üî¥ EXEMPLO ALTO RISCO\")\n",
        "prob_baixo = testar_predicao(exemplo_baixo_risco, \"üü¢ EXEMPLO BAIXO RISCO\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oITKuHXm52ZA",
        "outputId": "bf4ff478-26c3-4587-8758-54e44b3d2b15"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üß™ Testando fun√ß√£o de produ√ß√£o...\n",
            "\n",
            "üî¥ EXEMPLO ALTO RISCO:\n",
            "  Probabilidade de perda: 81.0%\n",
            "  Categoria de risco: Alto üî¥\n",
            "\n",
            "üü¢ EXEMPLO BAIXO RISCO:\n",
            "  Probabilidade de perda: 29.8%\n",
            "  Categoria de risco: Baixo üü¢\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 16. RESUMO FINAL E M√âTRICAS DO PROJETO\n"
      ],
      "metadata": {
        "id": "6smlaspq6Pv2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìã RESUMO FINAL DO PROJETO\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\"\"\n",
        "üéØ PROJETO LIGHTER TRACKER - SISTEMA DE PREDI√á√ÉO DE PERDA DE ISQUEIROS\n",
        "================================================================\n",
        "\n",
        "üìä DADOS:\n",
        "   ‚Ä¢ Base sint√©tica gerada: {len(df)} registros\n",
        "   ‚Ä¢ Per√≠odo: {df['data_compra'].min().strftime('%Y-%m-%d')} a {df['data_uso'].max().strftime('%Y-%m-%d')}\n",
        "   ‚Ä¢ Taxa de perda real: {df['perdeu'].mean()*100:.1f}%\n",
        "   ‚Ä¢ Features utilizadas: {len(all_features)} ({len(features_numericas)} num√©ricas + {len(features_categoricas)} categ√≥ricas)\n",
        "\n",
        "ü§ñ MODELO:\n",
        "   ‚Ä¢ Algoritmo: Regress√£o Log√≠stica\n",
        "   ‚Ä¢ Pr√©-processamento: StandardScaler + OneHotEncoder\n",
        "   ‚Ä¢ Balanceamento: class_weight='balanced'\n",
        "   ‚Ä¢ Otimiza√ß√£o: GridSearchCV (5-fold CV)\n",
        "\n",
        "üìà PERFORMANCE:\n",
        "   ‚Ä¢ Acur√°cia:     {accuracy*100:.2f}%\n",
        "   ‚Ä¢ Precis√£o:     {precision*100:.2f}%\n",
        "   ‚Ä¢ Recall:       {recall*100:.2f}%\n",
        "   ‚Ä¢ F1-Score:     {f1*100:.2f}%\n",
        "   ‚Ä¢ AUC-ROC:      {auc_roc*100:.2f}%\n",
        "\n",
        "üîç PRINCIPAIS INSIGHTS:\n",
        "   ‚Ä¢ Contextos de maior risco: Rua, Bar, Festa, Social\n",
        "   ‚Ä¢ Perfis de maior risco: Social, Espor√°dico\n",
        "   ‚Ä¢ Isqueiros descart√°veis s√£o perdidos mais facilmente\n",
        "   ‚Ä¢ Jovens (18-25) t√™m maior tend√™ncia √† perda\n",
        "   ‚Ä¢ Uso frequente aumenta risco (mais lugares = mais risco)\n",
        "\n",
        "üìÅ ARQUIVOS GERADOS:\n",
        "   ‚úÖ lighter_tracker_dados_brutos.csv - Base sint√©tica original\n",
        "   ‚úÖ lighter_tracker_com_predicoes.csv - Base com predi√ß√µes\n",
        "   ‚úÖ lighter_tracker_model.pkl - Modelo treinado para deploy\n",
        "   ‚úÖ model_info.json - Informa√ß√µes e m√©tricas do modelo\n",
        "   ‚úÖ lighter_tracker_predicao.py - C√≥digo para produ√ß√£o\n",
        "\n",
        "üöÄ APLICA√á√ÉO PR√ÅTICA:\n",
        "   ‚Ä¢ Sistema de recomenda√ß√µes em tempo real\n",
        "   ‚Ä¢ Alertas preventivos baseados em comportamento\n",
        "   ‚Ä¢ Insights para melhorar reten√ß√£o de isqueiros\n",
        "   ‚Ä¢ Interface amig√°vel com categoriza√ß√£o de risco\n",
        "\n",
        "üîÆ EXEMPLO DE PREDI√á√ÉO:\n",
        "   ‚Ä¢ Alto risco (jovem, bar, descart√°vel): {prob_alto*100:.1f}%\n",
        "   ‚Ä¢ Baixo risco (adulto, casa, recarreg√°vel): {prob_baixo*100:.1f}%\n",
        "\n",
        "================================================================\n",
        "‚úÖ PROJETO CONCLU√çDO COM SUCESSO!\n",
        "üí° Pronto para integra√ß√£o em sistema web/mobile\n",
        "üì± C√≥digo otimizado para deploy em produ√ß√£o\n",
        "\"\"\")\n",
        "\n",
        "print(\"\\nüéâ FIM DO NOTEBOOK - LIGHTER TRACKER ML PIPELINE\")\n",
        "print(\"=\" * 60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sylvg-iR6Rk6",
        "outputId": "329a25ef-693b-4a7c-816a-73eee839cb6a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "üìã RESUMO FINAL DO PROJETO\n",
            "============================================================\n",
            "\n",
            "üéØ PROJETO LIGHTER TRACKER - SISTEMA DE PREDI√á√ÉO DE PERDA DE ISQUEIROS\n",
            "================================================================\n",
            "\n",
            "üìä DADOS:\n",
            "   ‚Ä¢ Base sint√©tica gerada: 1200 registros\n",
            "   ‚Ä¢ Per√≠odo: 2024-09-17 a 2026-02-22\n",
            "   ‚Ä¢ Taxa de perda real: 50.5%\n",
            "   ‚Ä¢ Features utilizadas: 16 (7 num√©ricas + 9 categ√≥ricas)\n",
            "\n",
            "ü§ñ MODELO:\n",
            "   ‚Ä¢ Algoritmo: Regress√£o Log√≠stica\n",
            "   ‚Ä¢ Pr√©-processamento: StandardScaler + OneHotEncoder\n",
            "   ‚Ä¢ Balanceamento: class_weight='balanced'\n",
            "   ‚Ä¢ Otimiza√ß√£o: GridSearchCV (5-fold CV)\n",
            "\n",
            "üìà PERFORMANCE:\n",
            "   ‚Ä¢ Acur√°cia:     58.33%\n",
            "   ‚Ä¢ Precis√£o:     58.82%\n",
            "   ‚Ä¢ Recall:       57.85%\n",
            "   ‚Ä¢ F1-Score:     58.33%\n",
            "   ‚Ä¢ AUC-ROC:      62.22%\n",
            "\n",
            "üîç PRINCIPAIS INSIGHTS:\n",
            "   ‚Ä¢ Contextos de maior risco: Rua, Bar, Festa, Social\n",
            "   ‚Ä¢ Perfis de maior risco: Social, Espor√°dico\n",
            "   ‚Ä¢ Isqueiros descart√°veis s√£o perdidos mais facilmente\n",
            "   ‚Ä¢ Jovens (18-25) t√™m maior tend√™ncia √† perda\n",
            "   ‚Ä¢ Uso frequente aumenta risco (mais lugares = mais risco)\n",
            "\n",
            "üìÅ ARQUIVOS GERADOS:\n",
            "   ‚úÖ lighter_tracker_dados_brutos.csv - Base sint√©tica original\n",
            "   ‚úÖ lighter_tracker_com_predicoes.csv - Base com predi√ß√µes\n",
            "   ‚úÖ lighter_tracker_model.pkl - Modelo treinado para deploy\n",
            "   ‚úÖ model_info.json - Informa√ß√µes e m√©tricas do modelo\n",
            "   ‚úÖ lighter_tracker_predicao.py - C√≥digo para produ√ß√£o\n",
            "\n",
            "üöÄ APLICA√á√ÉO PR√ÅTICA:\n",
            "   ‚Ä¢ Sistema de recomenda√ß√µes em tempo real\n",
            "   ‚Ä¢ Alertas preventivos baseados em comportamento\n",
            "   ‚Ä¢ Insights para melhorar reten√ß√£o de isqueiros\n",
            "   ‚Ä¢ Interface amig√°vel com categoriza√ß√£o de risco\n",
            "\n",
            "üîÆ EXEMPLO DE PREDI√á√ÉO:\n",
            "   ‚Ä¢ Alto risco (jovem, bar, descart√°vel): 81.0%\n",
            "   ‚Ä¢ Baixo risco (adulto, casa, recarreg√°vel): 29.8%\n",
            "\n",
            "================================================================\n",
            "‚úÖ PROJETO CONCLU√çDO COM SUCESSO!\n",
            "üí° Pronto para integra√ß√£o em sistema web/mobile\n",
            "üì± C√≥digo otimizado para deploy em produ√ß√£o\n",
            "\n",
            "\n",
            "üéâ FIM DO NOTEBOOK - LIGHTER TRACKER ML PIPELINE\n",
            "============================================================\n"
          ]
        }
      ]
    }
  ]
}